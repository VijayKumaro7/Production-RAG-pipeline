# ============================================================
# Production RAG Pipeline — Master Configuration
# ============================================================

# --- Document Ingestion ---
ingestion:
  supported_formats: ["pdf", "txt", "docx"]
  chunk_strategy: "recursive"      # options: fixed, recursive, sentence
  chunk_size: 512
  chunk_overlap: 50

# --- Embeddings ---
embeddings:
  provider: "huggingface"          # options: openai, huggingface
  openai_model: "text-embedding-ada-002"
  huggingface_model: "all-MiniLM-L6-v2"
  batch_size: 64

# --- Vector Store ---
vector_store:
  provider: "chroma"               # options: chroma, faiss
  chroma_persist_dir: "./data/chroma_db"
  faiss_index_path: "./data/faiss_index"
  collection_name: "rag_documents"

# --- Retrieval ---
retrieval:
  method: "similarity"             # options: similarity, mmr
  top_k: 4
  mmr_lambda: 0.5                  # diversity factor for MMR (0=max diversity, 1=max relevance)
  score_threshold: 0.0

# --- LLM Generation ---
llm:
  provider: "openai"               # options: openai, ollama, google
  openai_model: "gpt-3.5-turbo"
  ollama_model: "mistral"
  google_model: "gemini-pro"
  temperature: 0.0
  max_tokens: 512

# --- Evaluation ---
evaluation:
  metrics:
    - faithfulness
    - answer_relevancy
    - context_recall
    - context_precision
  test_questions_path: "./evaluation/test_questions.json"
  results_dir: "./experiments/results"

# --- Bonus Features ---
advanced:
  query_expansion: false           # Rewrite query using LLM before retrieval
  reranking: false                 # CrossEncoder re-ranking after initial retrieval
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  hallucination_threshold: 0.5    # Faithfulness score below this → flag as hallucination

# --- Logging ---
logging:
  level: "INFO"
  log_file: "./logs/pipeline.log"
